{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# reload magics\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datasets\n",
    "from project_modules.io import load_dataset_to_df\n",
    "from project_modules.classifcation import classify_MP,getXY, boruta_fs\n",
    "from project_modules.utils import MPutils\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import multiprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import cupy as cp\n",
    "from datetime import datetime\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "import umap\n",
    "import matplotlib.colors as mc\n",
    "\n",
    "import colorcet as cc\n",
    "from sklearn.pipeline import Pipeline\n",
    "# clustering\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.manifold import TSNE\n",
    "import json\n",
    "\n",
    "import shap\n",
    "import pickle\n",
    "\n",
    "# from project_modules.utils import get_logger\n",
    "# logger = get_logger(\"log-data-combine-split.log\")\n",
    "# # read the parameter file\n",
    "\n",
    "# from project_modules.utils import read_parameters\n",
    "# parms = read_parameters(\"/Users/david/projects/lc-project-data/project.yaml\")\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lScorersBinary = [\n",
    "    \"accuracy\",\n",
    "    \"balanced_accuracy\",\n",
    "    \"roc_auc\",\n",
    "    \"f1\",\n",
    "    \"recall\",\n",
    "    \"sensitivity\",\n",
    "    \"specificity\",\n",
    "    \"precision\",\n",
    "    # \"average_precision\",\n",
    "    \"NPV\",\n",
    "    \"PPV\",\n",
    "    # \"neg_mean_squared_error\",\n",
    "]\n",
    "lResCol = [\n",
    "    \"Title\",\n",
    "    \"cv\",\n",
    "    \"param_clf\",\n",
    "    \"param_clf__max_depth\",\n",
    "    \"param_clf__n_estimators\",\n",
    "    \"param_clf__random_state\",\n",
    "    # \"param_clf__max_iter\",\n",
    "    \"mean_test_accuracy\",\n",
    "    \"mean_test_balanced_accuracy\",\n",
    "    \"mean_test_roc_auc\",\n",
    "    \"mean_test_f1\",\n",
    "    \"mean_test_recall\",\n",
    "    \"mean_test_sensitivity\",\n",
    "    \"mean_test_specificity\",\n",
    "    \"mean_test_precision\",\n",
    "    \"mean_test_NPV\",\n",
    "    \"mean_test_PPV\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lDataNames = ['T81','T85','DT']\n",
    "\n",
    "\n",
    "lDataNames = [\n",
    "    \"dfcmpltPreLC4\",  # Done\n",
    "    \"dfcmpltPreLC4_SITE1\",  # Done\n",
    "    \"dfcmpltPreLC4_SITE2\",  # Done\n",
    "    \"dfcmpltPreLC4_SITE3\",  # Done\n",
    "    \"dfcmpltPreLC4_SITE4\",  # Done\n",
    "    \"dfcmpltPreLC4_SITE5\",  # LEFT\n",
    "    \"dfcmpltPreLC4_SITE6\",  # LEFT\n",
    "    \"dfcmpltPreLC4_SITE7\",  # LEFT\n",
    "]\n",
    "dataDir = \"../Data/DataV4/TTS/\"\n",
    "saveDir = MPutils.get_saving_dir('OUTPUT/MP/05-classifiers/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_name_dict = {1: \"LDN\", 2: \"MTL\", 3: \"SAN\", 4: \"RIO\", 5: \"LUS\", 6: \"CA\", 7: \"NA\"}\n",
    "status_name_dict = {\n",
    "    0: \"LC_NEG\",\n",
    "    1: \"LC_POS\",\n",
    "    2: \"HC\",\n",
    "}\n",
    "# assign consistent styles\n",
    "site_style = {\n",
    "              1: 'D',\n",
    "              2: 'o',\n",
    "              3: 'P',\n",
    "              4: 'X',\n",
    "              5: 's',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = cc.glasbey_hv\n",
    "\n",
    "# create a palette dictionary that has the same keys as the original palette\n",
    "palette_dict = {i: mc.to_hex(palette[i]) for i in range(len(palette))} # type: ignore\n",
    "\n",
    "# add an entry for -1\n",
    "palette_dict[-1] = '#ffffff'\n",
    "\n",
    "# set default colour for seaborn heatmaps\n",
    "sns.set_theme(style = \"whitegrid\", rc={'figure.figsize':(8,8)}, palette='viridis')\n",
    "\n",
    "with open('JSON/selectFeaturePalette.json') as f: paletteSel = json.load(f)\n",
    "with open('JSON/selectFeaturePalette_NiceFeat.json') as f: paletteSel_NF = json.load(f)\n",
    "with open('JSON/selectFeaturePalette_NiceFeatFlipped.json') as f: paletteSel_NFF = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_categorical_colours(df, palette=cc.glasbey_hv):\n",
    "\n",
    "    # make a list of colours\n",
    "    colours_dict = {feature: palette[i] for i, feature in enumerate(df.columns)}\n",
    "    return colours_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data and run clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE - MATCH with 05.2 holdout classifiers and the best features exported by 05.1\n",
    "globalfeat = \"FS_dfcmpltPreLC4_Boruta_T1000_itrr500_th100_topR5_MD3\"\n",
    "valSelTests = {\n",
    "    \"dfcmpltPreLC4\": {\"featlist\": globalfeat, \"site\": \"Global\"},\n",
    "    \"dfcmpltPreLC4_SITE1\": {\n",
    "        \"featlist\": globalfeat,\n",
    "        \"site\": \"London\",\n",
    "    },\n",
    "    \"dfcmpltPreLC4_SITE2\": {\n",
    "        \"featlist\": globalfeat,\n",
    "        \"site\": \"Montreal\",\n",
    "    },\n",
    "    \"dfcmpltPreLC4_SITE3\": {\n",
    "        \"featlist\": globalfeat,\n",
    "        \"site\": \"San Diego\",\n",
    "    },\n",
    "    \"dfcmpltPreLC4_SITE4\": {\n",
    "        \"featlist\": globalfeat,\n",
    "        \"site\": \"Rio\",\n",
    "    },\n",
    "    # \"dfcmpltPreLC4_SITE5\": {\"featlist\": globalfeat, \"site\": \"Lusaka\"},\n",
    "    # \"dfcmpltPreLC4_SITE6\": {\n",
    "    #     \"featlist\": globalfeat,\n",
    "    #     \"site\": \"Canada\",\n",
    "    # },\n",
    "    # \"dfcmpltPreLC4_SITE7\": {\n",
    "    #     \"featlist\": globalfeat,\n",
    "    #     \"site\": \"NorthAmerica\",\n",
    "    # },\n",
    "    \"dfcmpltPreLC4_SITE1_siteFeat\": {\n",
    "        \"featlist\": \"FS_dfcmpltPreLC4_SITE1_Boruta_T1000_itrr500_th100_topR5_MD3\",\n",
    "        \"site\": \"London\",\n",
    "    },\n",
    "    \"dfcmpltPreLC4_SITE2_siteFeat\": {\n",
    "        \"featlist\": \"FS_dfcmpltPreLC4_SITE2_Boruta_T1000_itrr500_th100_topR5_MD5\",\n",
    "        \"site\": \"Montreal\",\n",
    "    },\n",
    "    \"dfcmpltPreLC4_SITE3_siteFeat\": {\n",
    "        \"featlist\": \"FS_dfcmpltPreLC4_SITE3_Boruta_T1000_itrr500_th100_topR5_MD3\",\n",
    "        \"site\": \"San Diego\",\n",
    "    },\n",
    "    \"dfcmpltPreLC4_SITE4_siteFeat\": {\n",
    "        \"featlist\": \"FS_dfcmpltPreLC4_SITE4_Boruta_T1000_itrr500_th100_topR5_MD3\",\n",
    "        \"site\": \"Rio\",\n",
    "    },\n",
    "    # \"dfcmpltPreLC4_SITE5_siteFeat\": {\"featlist\": globalfeat, \"site\": \"Lusaka\"},\n",
    "    # \"dfcmpltPreLC4_SITE6_siteFeat\": {\n",
    "    #     \"featlist\": globalfeat,\n",
    "    #     \"site\": \"Canada\",\n",
    "    # },\n",
    "    # \"dfcmpltPreLC4_SITE7_siteFeat\": {\n",
    "    #     \"featlist\": globalfeat,\n",
    "    #     \"site\": \"NorthAmerica\",\n",
    "    # },\n",
    "}\n",
    "valSelKeys = [ \n",
    " 'dfcmpltPreLC4',\n",
    " 'dfcmpltPreLC4_SITE1',\n",
    " 'dfcmpltPreLC4_SITE2',\n",
    " 'dfcmpltPreLC4_SITE3',\n",
    " 'dfcmpltPreLC4_SITE4',\n",
    "#  'dfcmpltPreLC4_SITE5',\n",
    "#  'dfcmpltPreLC4_SITE6',\n",
    "#  'dfcmpltPreLC4_SITE7'\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4d6e00b4f464f20b65c2ed3b7f3b9f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DataSet Main Outer Loop:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for selData in tqdm(valSelTests.keys(),desc='DataSet Main Outer Loop'):\n",
    "\n",
    "    tmpDict = valSelTests[selData] # get site Dict\n",
    "    selFeatName = tmpDict['featlist'] #get site feature file\n",
    "\n",
    "    # load df\n",
    "    df_h = load_dataset_to_df(f\"{dataDir}{selData.replace('_siteFeat','')}_Holdout.arrow\", verbose=True)\n",
    "    df_Tr = load_dataset_to_df(\n",
    "        f\"{dataDir}{selData.replace('_siteFeat','')}_Train.arrow\", verbose=True\n",
    "    )\n",
    "\n",
    "    df_h.drop(df_h[df_h[\"LC_STATUS\"] == 2].index, inplace=True)  # drop HC\n",
    "\n",
    "    # drop columns\n",
    "    lColDrop = [\"__index_level_0__\", \"LC_STATUS_SITE\",'SITE']\n",
    "    for c in lColDrop:\n",
    "        if c in df_h.columns:\n",
    "            df_h.drop(columns=[c], inplace=True)\n",
    "\n",
    "    tmpDict['data'] = df_h #store data\n",
    "\n",
    "    # init saving dir\n",
    "    tmpDict['savedir'] = MPutils.get_saving_dir(\n",
    "        f\"OUTPUT/MP/05-classifiers/DataV4/{selData}/\"\n",
    "    )\n",
    "\n",
    "    # get Sel Cols\n",
    "    tmpDict['featDir']= selFeatName.replace('FS_','').split('_Boruta')[0]\n",
    "    tmpDict['selCols']= MPutils.getTrueFeatList(f\"OUTPUT/MP/05-classifiers/DataV4/{tmpDict['featDir']}/{selFeatName}.csv\")\n",
    "\n",
    "    # get x and y\n",
    "    x_h, y_h = getXY(df_h)\n",
    "    tmpDict['x_h']=x_h[tmpDict['selCols']]# select Boruta Cols and store\n",
    "    tmpDict['y_h']=y_h #store labels\n",
    "\n",
    "    # get x and y\n",
    "    x_Tr, y_Tr = getXY(df_Tr)\n",
    "    tmpDict['x_Tr']=x_Tr[tmpDict['selCols']]# select Boruta Cols and store\n",
    "    tmpDict['y_Tr']=y_Tr #store labels\n",
    "\n",
    "    scaler = MinMaxScaler().set_output(transform=\"pandas\")\n",
    "    x_h_scaled = scaler.fit_transform(tmpDict[\"x_h\"])\n",
    "\n",
    "    tmpDict[\"x_h_scaled\"] = x_h_scaled\n",
    "\n",
    "    with open(\n",
    "        f\"./OUTPUT/MP/05-classifiers/DataV4/generatedHoldoutDataDicts/{selData}.pickle\",\n",
    "        \"wb\",\n",
    "    ) as handle:\n",
    "        pickle.dump(tmpDict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clust",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
