{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload magics\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datasets\n",
    "from project_modules.io import load_dataset_to_df\n",
    "from project_modules.classifcation import classify_MP,getXY, boruta_fs\n",
    "from project_modules.utils import MPutils\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import multiprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import cupy as cp\n",
    "from datetime import datetime\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# from project_modules.utils import get_logger\n",
    "# logger = get_logger(\"log-data-combine-split.log\")\n",
    "# # read the parameter file\n",
    "\n",
    "# from project_modules.utils import read_parameters\n",
    "# parms = read_parameters(\"/Users/david/projects/lc-project-data/project.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# input_path = Path(\"../lc-project-data\")\n",
    "# output_path = Path(\"../lc-project-data\")\n",
    "\n",
    "# for MP,\n",
    "# input_path = Path(\"../Data/DataV3\")\n",
    "# output_path = Path(\"OUTPUT/MP/05-classifiers/DataV3/\")\n",
    "\n",
    "#DataV4 - 2024-10-09 - Dropped patients with missing vax data\n",
    "input_path = Path(\"../Data/DataV4\")\n",
    "output_path = Path(\"OUTPUT/MP/05-classifiers/DataV4/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lScorersBinary = [\n",
    "    \"accuracy\",\n",
    "    \"balanced_accuracy\",\n",
    "    \"roc_auc\",\n",
    "    \"f1\",\n",
    "    \"recall\",\n",
    "    \"sensitivity\",\n",
    "    \"specificity\",\n",
    "    \"precision\",\n",
    "    # \"average_precision\",\n",
    "    \"NPV\",\n",
    "    \"PPV\",\n",
    "    # \"neg_mean_squared_error\",\n",
    "]\n",
    "lResCol = [\n",
    "    \"Title\",\n",
    "    \"cv\",\n",
    "    \"param_clf\",\n",
    "    \"param_clf__max_depth\",\n",
    "    \"param_clf__n_estimators\",\n",
    "    \"param_clf__random_state\",\n",
    "    # \"param_clf__max_iter\",\n",
    "    \"mean_test_accuracy\",\n",
    "    \"mean_test_balanced_accuracy\",\n",
    "    \"mean_test_roc_auc\",\n",
    "    \"mean_test_f1\",\n",
    "    \"mean_test_recall\",\n",
    "    \"mean_test_sensitivity\",\n",
    "    \"mean_test_specificity\",\n",
    "    \"mean_test_precision\",\n",
    "    \"mean_test_NPV\",\n",
    "    \"mean_test_PPV\",\n",
    "]\n",
    "\n",
    "lPrettyCols = [\n",
    "    \"MainDataset\",\n",
    "    \"RunType\",\n",
    "    \"classifier\",\n",
    "    \"brt_nTrue\",\n",
    "    \"brt_nTop\",\n",
    "    \"accuracy\",\n",
    "    \"balanced_accuracy\",\n",
    "    \"roc_auc\",\n",
    "    \"f1\",\n",
    "    \"recall\",\n",
    "    \"sensitivity\",\n",
    "    \"specificity\",\n",
    "    \"precision\",\n",
    "    \"NPV\",\n",
    "    \"PPV\",\n",
    "    \"brt_md\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lDataNames = ['T81','T85','DT']\n",
    "\n",
    "\n",
    "lDataNames = [\n",
    "    # \"dfcmplt\", # Done\n",
    "    # \"dfcmplt_SITE1\", # Done\n",
    "    # \"dfcmplt_SITE2\", # Done\n",
    "    # \"dfcmplt_SITE3\", # Done\n",
    "    # \"dfcmplt_SITE4\", # Done\n",
    "    # \"dfcmplt_SITE5\",  # LEFT\n",
    "    # \"dfcmplt_SITE6\",  # LEFT\n",
    "    # \"dfcmplt_SITE7\",  # LEFT\n",
    "    # \"dfcmpltPreLC\",  # Done\n",
    "    # \"dfcmpltPreLC_SITE1\", # Done\n",
    "    # \"dfcmpltPreLC_SITE2\", # Done\n",
    "    # \"dfcmpltPreLC_SITE3\", # Done\n",
    "    # \"dfcmpltPreLC_SITE4\", # Done\n",
    "    # \"dfcmpltPreLC_SITE5\",  # Done\n",
    "    # \"dfcmpltPreLC_SITE6\",  # Done\n",
    "    # \"dfcmpltPreLC_SITE7\",  # Done\n",
    "    # \"dfcmpltPreLC2\",  # Done\n",
    "    # \"dfcmpltPreLC2_SITE1\", # Done\n",
    "    # \"dfcmpltPreLC2_SITE2\", # Done\n",
    "    # \"dfcmpltPreLC2_SITE3\", # Done\n",
    "    # \"dfcmpltPreLC2_SITE4\", # Done\n",
    "    # \"dfcmpltPreLC2_SITE5\",  # Done\n",
    "    # \"dfcmpltPreLC2_SITE6\",  # Done\n",
    "    # \"dfcmpltPreLC2_SITE7\",  # Done\n",
    "    # \"dfcmpltPreLC3\",  # Done\n",
    "    # \"dfcmpltPreLC3_SITE1\", # Done\n",
    "    # \"dfcmpltPreLC3_SITE2\", # Done\n",
    "    # \"dfcmpltPreLC3_SITE3\", # Done\n",
    "    # \"dfcmpltPreLC3_SITE4\", # Done\n",
    "    # \"dfcmpltPreLC3_SITE5\",  # Done\n",
    "    # \"dfcmpltPreLC3_SITE6\",  # Done\n",
    "    # \"dfcmpltPreLC3_SITE7\",  # Done\n",
    "    # \"dfcmpltPreLC4\",  # Done\n",
    "    # \"dfcmpltPreLC4_SITE1\", # Done\n",
    "    # \"dfcmpltPreLC4_SITE2\", # Done\n",
    "    # \"dfcmpltPreLC4_SITE3\", # Done\n",
    "    \"dfcmpltPreLC4_SITE4\", # Done\n",
    "    # \"dfcmpltPreLC4_SITE5\",  # \n",
    "    # \"dfcmpltPreLC4_SITE6\",  # \n",
    "    # \"dfcmpltPreLC4_SITE7\",  # \n",
    "]\n",
    "dataDir = \"../Data/DataV4/TTS/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saveDir = MPutils.get_saving_dir(f\"OUTPUT/MP/05-classifiers/DataV2/{dataName}/\")\n",
    "\n",
    "\n",
    "lClassifiers = [\"RF\", \"LogR\",'XGBcpu'] # different classifiers #NOTE - XGBcpu is faster than XGBcuda for some reason?\n",
    "lCV = [5] # different cross-validation splits\n",
    "lTrees=[100,1000] #num trees\n",
    "lMD=[3,6,10,15, None] #max depth\n",
    "\n",
    "lBrt_MD = [3, 5, 7]\n",
    "brt_trees = 1000\n",
    "brt_iter = 500\n",
    "brt_thres = 100\n",
    "brt_toprank = 5\n",
    "\n",
    "\n",
    "# FIXME - BELOW CODE FOR TESTING PURPOSES\n",
    "# dataName = 'dfcmplt'\n",
    "# lClassifiers = [\n",
    "#     \"RF\",\n",
    "#     \"LogR\",\n",
    "#     \"XGBcpu\",\n",
    "# ]  # different classifiers #NOTE - XGBcpu is faster than XGBcuda for some reason?\n",
    "# lCV = [5]  # different cross-validation splits\n",
    "# lTrees = [10]  # num trees\n",
    "# lMD = [3]  # max depth\n",
    "\n",
    "# lBrt_MD = [4]\n",
    "# brt_trees=12\n",
    "# brt_iter = 10\n",
    "# brt_thres=100\n",
    "# brt_toprank=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated ML BRT and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def updateExistingDF(dfTmp, fileName, save=False):\n",
    "    if os.path.exists(fileName):\n",
    "        dfTmp = pd.concat([dfTmp, pd.read_csv(fileName)])\n",
    "        if 'params' in dfTmp.columns:\n",
    "            dfTmp[\"params\"] = dfTmp[\"params\"].iloc[0].__str__()\n",
    "        dfTmp = dfTmp.drop_duplicates(\n",
    "             subset=[x for x in dfTmp.columns if x != \"param_clf\" and x!='date' and 'split' not in x and '_time' not in x and 'rank_' not in x and 'std' not in x]\n",
    "        )\n",
    "    if save:\n",
    "        dfTmp.to_csv(fileName, index=False)\n",
    "\n",
    "    return dfTmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d36b905c9794424a62ccbbc24791832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DataSet Main Outer Loop:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbf6bf4536ae407fae7f77b878d4e2f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Boruta MD Loop:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd36d3f2ce1d487ea7dc91512d0e36a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Boruta MD Loop:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lRunDataFrames = []\n",
    "for dataName in tqdm(lDataNames,desc='DataSet Main Outer Loop'):\n",
    "\n",
    "    df_tr = load_dataset_to_df(f\"{dataDir}{dataName}_Train.arrow\", verbose=True)\n",
    "    df_ts = load_dataset_to_df(f\"{dataDir}{dataName}_Test.arrow\", verbose=True)\n",
    "    df_h = load_dataset_to_df(f\"{dataDir}{dataName}_Holdout.arrow\", verbose=True)\n",
    "    df_full = pd.concat([df_tr,df_ts,df_h])\n",
    "\n",
    "    lColDrop = [\"__index_level_0__\", \"LC_STATUS_SITE\",'SITE']\n",
    "\n",
    "    for df in [df_tr,df_ts,df_h,df_full]:\n",
    "        df.drop(df[df[\"LC_STATUS\"] == 2].index, inplace=True)  # drop HC\n",
    "        for c in lColDrop:\n",
    "            if c in df.columns:\n",
    "                df.drop(columns=[c],inplace=True)\n",
    "        ##Depreciated below based on doing this in the splice data\n",
    "        # df[\"LC_STATUS\"] = df[\"LC_STATUS\"].apply(\n",
    "        #     lambda x: 1 if x == \"LC_POS\" else 0\n",
    "        # )  # Convert to 0==LCNeg, 1==LCPos\n",
    "        # df.drop(columns=lColDrop, inplace=True)  # drop unneeded columns\n",
    "\n",
    "    saveDir = MPutils.get_saving_dir(\n",
    "        f\"OUTPUT/MP/05-classifiers/DataV4/{dataName}/\"\n",
    "    )\n",
    "\n",
    "    ## HOLDOUT SET ONLY\n",
    "    x_h, y_h = getXY(df_h)\n",
    "\n",
    "    # Ensure all arguments are picklable -- due to BrokenProcessPool: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n",
    "    picklable_lScorers = [scorer for scorer in lScorersBinary]\n",
    "    picklable_lClassifiers = [classifier for classifier in lClassifiers]\n",
    "\n",
    "    dfRHold = classify_MP(\n",
    "        X=x_h,\n",
    "        y=y_h,\n",
    "        lScorers=picklable_lScorers,\n",
    "        lClassifiers=picklable_lClassifiers,\n",
    "        lTrees=lTrees,\n",
    "        lMD=lMD,\n",
    "        lCV=lCV,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    dfRHold[\"Title\"] = f\"{dataName}_Holdout\"\n",
    "    dfRHold['RunType']='Holdout'\n",
    "\n",
    "    dfRHold[\"MainDataset\"] = dataName\n",
    "    dfRHold[\"date\"] = datetime.today()\n",
    "\n",
    "    holdFile = f\"{saveDir}CA_{dataName}_Holdout.csv\"\n",
    "    dfRHold = updateExistingDF(dfRHold, holdFile, save=True)\n",
    "\n",
    "    ## Full SET ONLY\n",
    "    x_F, y_F = getXY(df_full)\n",
    "\n",
    "    dfRFull = classify_MP(\n",
    "        X=x_F,\n",
    "        y=y_F,\n",
    "        lScorers=lScorersBinary,\n",
    "        lClassifiers=lClassifiers,\n",
    "        lTrees=lTrees,\n",
    "        lMD=lMD,\n",
    "        lCV=lCV,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    dfRFull[\"Title\"] = f\"{dataName}_Full\"\n",
    "    dfRFull[\"RunType\"] = \"Full\"\n",
    "    dfRFull[\"MainDataset\"] = dataName\n",
    "    dfRFull[\"date\"] = datetime.today()\n",
    "\n",
    "    fulldataFile= f\"{saveDir}CA_{dataName}_Full.csv\"\n",
    "    dfRFull = updateExistingDF(dfRFull, fulldataFile, save=True)\n",
    "\n",
    "    ## SECTION BORUTA Feature Selection\n",
    "\n",
    "    x_Tr, y_Tr = getXY(df_tr)\n",
    "    lBrtResults = []\n",
    "    for boruta_md in tqdm(lBrt_MD[:],desc='Boruta MD Loop'):\n",
    "        # run brouta = get true and top feat\n",
    "        trueFeat, topFeat = boruta_fs(\n",
    "            X=x_Tr.values,\n",
    "            y=y_Tr,\n",
    "            feat_list=x_Tr.columns,\n",
    "            trees=brt_trees,\n",
    "            ittr=brt_iter,\n",
    "            threshold=brt_thres,\n",
    "            top_rank=brt_toprank,\n",
    "            verbose=0,\n",
    "            model=RandomForestClassifier(\n",
    "                n_jobs=-1, class_weight=\"balanced\", max_depth=boruta_md, random_state=42\n",
    "            ),\n",
    "            fileName=f\"{saveDir}FS_{dataName}_Boruta_T{brt_trees}_itrr{brt_iter}_th{brt_thres}_topR{brt_toprank}_MD{boruta_md}.csv\",\n",
    "        )\n",
    "\n",
    "        ## Test Brouta Features\n",
    "        x_TsMain, y_Ts = getXY(df_ts)\n",
    "\n",
    "        x_Ts_True = x_TsMain[trueFeat]\n",
    "        x_Ts_Top = x_TsMain[topFeat]\n",
    "\n",
    "        # SECTION - True Feat\n",
    "        if len(trueFeat) > 0:\n",
    "            dfR_True = classify_MP(\n",
    "                X=x_Ts_True,\n",
    "                y=y_Ts,\n",
    "                lScorers=lScorersBinary,\n",
    "                lClassifiers=lClassifiers,\n",
    "                lTrees=lTrees,\n",
    "                lMD=lMD,\n",
    "                lCV=lCV,\n",
    "                n_jobs=-1,\n",
    "            )\n",
    "            dfR_True[\"Title\"] = f\"{dataName}_Boruta_True\"\n",
    "            dfR_True[\"brt_md\"] = boruta_md\n",
    "            dfR_True['brt_nTrue'] = len(trueFeat)\n",
    "            dfR_True['brt_nTop'] = len(topFeat)\n",
    "            dfR_True[\"RunType\"] = \"Boruta_True\"\n",
    "            lBrtResults.append(dfR_True)\n",
    "\n",
    "        # SECTION - Top Feat\n",
    "        if len(topFeat) > 0:\n",
    "            dfR_Top = classify_MP(\n",
    "                X=x_Ts_Top,\n",
    "                y=y_Ts,\n",
    "                lScorers=lScorersBinary,\n",
    "                lClassifiers=lClassifiers,\n",
    "                lTrees=lTrees,\n",
    "                lMD=lMD,\n",
    "                lCV=lCV,\n",
    "                n_jobs=-1,\n",
    "            )\n",
    "            dfR_Top[\"Title\"] = f\"{dataName}_Boruta_Top\"\n",
    "\n",
    "            dfR_Top[\"brt_md\"] = boruta_md\n",
    "            dfR_Top['brt_nTrue'] = len(trueFeat)\n",
    "            dfR_Top[\"brt_nTop\"] = len(topFeat)\n",
    "            dfR_Top[\"RunType\"] = \"Boruta_Top\"\n",
    "            lBrtResults.append(dfR_Top)\n",
    "\n",
    "    dfCLFRun = pd.concat([dfRHold, dfRFull]+lBrtResults)\n",
    "\n",
    "    dfCLFRun[\"MainDataset\"] = dataName\n",
    "    dfCLFRun[\"date\"] = datetime.today()\n",
    "    dfCLFRun[\"brt_params\"] = (\n",
    "        f\"T{brt_trees}_itrr{brt_iter}_th{brt_thres}_topR{brt_toprank}\"\n",
    "    )\n",
    "\n",
    "    clfFile = f\"{saveDir}CLFRun_{dataName}_Results.csv\"\n",
    "\n",
    "    dfCLFRun = updateExistingDF(dfCLFRun,clfFile,save=False)\n",
    "    dfCLFRun = MPutils.reorder_columns(dfCLFRun, [\"MainDataset\", \"Title\", \"date\",'brt_nTrue','brt_nTop'])\n",
    "    dfCLFRun.to_csv(clfFile, index=False)\n",
    "\n",
    "    # lRunDataFrames.append(dfCLFRun)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clust",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
