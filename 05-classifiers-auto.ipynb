{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload magics\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datasets\n",
    "from project_modules.io import load_dataset_to_df\n",
    "from project_modules.classifcation import classify_MP,getXY, boruta_fs\n",
    "from project_modules.utils import MPutils\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import multiprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import cupy as cp\n",
    "from datetime import datetime\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# from project_modules.utils import get_logger\n",
    "# logger = get_logger(\"log-data-combine-split.log\")\n",
    "# # read the parameter file\n",
    "\n",
    "# from project_modules.utils import read_parameters\n",
    "# parms = read_parameters(\"/Users/david/projects/lc-project-data/project.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# input_path = Path(\"../lc-project-data\")\n",
    "# output_path = Path(\"../lc-project-data\")\n",
    "\n",
    "# for MP,\n",
    "# input_path = Path(\"../Data/DataV3\")\n",
    "# output_path = Path(\"OUTPUT/MP/05-classifiers/DataV3/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lScorersBinary = [\n",
    "    \"accuracy\",\n",
    "    \"balanced_accuracy\",\n",
    "    \"roc_auc\",\n",
    "    \"f1\",\n",
    "    \"recall\",\n",
    "    \"sensitivity\",\n",
    "    \"specificity\",\n",
    "    \"precision\",\n",
    "    # \"average_precision\",\n",
    "    \"NPV\",\n",
    "    \"PPV\",\n",
    "    # \"neg_mean_squared_error\",\n",
    "]\n",
    "lResCol = [\n",
    "    \"Title\",\n",
    "    \"cv\",\n",
    "    \"param_clf\",\n",
    "    \"param_clf__max_depth\",\n",
    "    \"param_clf__n_estimators\",\n",
    "    \"param_clf__random_state\",\n",
    "    # \"param_clf__max_iter\",\n",
    "    \"mean_test_accuracy\",\n",
    "    \"mean_test_balanced_accuracy\",\n",
    "    \"mean_test_roc_auc\",\n",
    "    \"mean_test_f1\",\n",
    "    \"mean_test_recall\",\n",
    "    \"mean_test_sensitivity\",\n",
    "    \"mean_test_specificity\",\n",
    "    \"mean_test_precision\",\n",
    "    \"mean_test_NPV\",\n",
    "    \"mean_test_PPV\",\n",
    "]\n",
    "\n",
    "lPrettyCols = [\n",
    "    \"MainDataset\",\n",
    "    \"RunType\",\n",
    "    \"classifier\",\n",
    "    \"brt_nTrue\",\n",
    "    \"brt_nTop\",\n",
    "    \"accuracy\",\n",
    "    \"balanced_accuracy\",\n",
    "    \"roc_auc\",\n",
    "    \"f1\",\n",
    "    \"recall\",\n",
    "    \"sensitivity\",\n",
    "    \"specificity\",\n",
    "    \"precision\",\n",
    "    \"NPV\",\n",
    "    \"PPV\",\n",
    "    \"brt_md\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lDataNames = ['T81','T85','DT']\n",
    "\n",
    "\n",
    "lDataNames = [\n",
    "    # \"dfcmplt\", # Done\n",
    "    # \"dfcmplt_SITE1\", # Done\n",
    "    # \"dfcmplt_SITE2\", # Done\n",
    "    # \"dfcmplt_SITE3\", # Done\n",
    "    # \"dfcmplt_SITE4\", # Done\n",
    "    # \"dfcmplt_SITE5\",  # LEFT\n",
    "    # \"dfcmplt_SITE6\",  # LEFT\n",
    "    # \"dfcmplt_SITE7\",  # LEFT\n",
    "    # \"dfcmpltPreLC\",  # Done\n",
    "    # \"dfcmpltPreLC_SITE1\", # Done\n",
    "    # \"dfcmpltPreLC_SITE2\", # Done\n",
    "    # \"dfcmpltPreLC_SITE3\", # Done\n",
    "    # \"dfcmpltPreLC_SITE4\", # Done\n",
    "    # \"dfcmpltPreLC_SITE5\",  # Done\n",
    "    # \"dfcmpltPreLC_SITE6\",  # Done\n",
    "    # \"dfcmpltPreLC_SITE7\",  # Done\n",
    "    # \"dfcmpltPreLC2\",  # Done\n",
    "    # \"dfcmpltPreLC2_SITE1\", # Done\n",
    "    # \"dfcmpltPreLC2_SITE2\", # Done\n",
    "    # \"dfcmpltPreLC2_SITE3\", # Done\n",
    "    # \"dfcmpltPreLC2_SITE4\", # Done\n",
    "    # \"dfcmpltPreLC2_SITE5\",  # Done\n",
    "    # \"dfcmpltPreLC2_SITE6\",  # Done\n",
    "    # \"dfcmpltPreLC2_SITE7\",  # Done\n",
    "    \"dfcmpltPreLC3\",  # Done\n",
    "    \"dfcmpltPreLC3_SITE1\", # Done\n",
    "    \"dfcmpltPreLC3_SITE2\", # Done\n",
    "    \"dfcmpltPreLC3_SITE3\", # Done\n",
    "    \"dfcmpltPreLC3_SITE4\", # Done\n",
    "    \"dfcmpltPreLC3_SITE5\",  # Done\n",
    "    \"dfcmpltPreLC3_SITE6\",  # Done\n",
    "    \"dfcmpltPreLC3_SITE7\",  # Done\n",
    "]\n",
    "dataDir = \"../Data/DataV3/TTS/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saveDir = MPutils.get_saving_dir(f\"OUTPUT/MP/05-classifiers/DataV2/{dataName}/\")\n",
    "\n",
    "\n",
    "lClassifiers = [\"RF\", \"LogR\",'XGBcpu'] # different classifiers #NOTE - XGBcpu is faster than XGBcuda for some reason?\n",
    "lCV = [5] # different cross-validation splits\n",
    "lTrees=[100,1000] #num trees\n",
    "lMD=[3,6,10,15, None] #max depth\n",
    "\n",
    "lBrt_MD = [3, 5, 7]\n",
    "brt_trees = 1000\n",
    "brt_iter = 500\n",
    "brt_thres = 100\n",
    "brt_toprank = 5\n",
    "\n",
    "\n",
    "# FIXME - BELOW CODE FOR TESTING PURPOSES\n",
    "# dataName = 'dfcmplt'\n",
    "# lClassifiers = [\n",
    "#     \"RF\",\n",
    "#     \"LogR\",\n",
    "#     \"XGBcpu\",\n",
    "# ]  # different classifiers #NOTE - XGBcpu is faster than XGBcuda for some reason?\n",
    "# lCV = [5]  # different cross-validation splits\n",
    "# lTrees = [10]  # num trees\n",
    "# lMD = [3]  # max depth\n",
    "\n",
    "# lBrt_MD = [4]\n",
    "# brt_trees=12\n",
    "# brt_iter = 10\n",
    "# brt_thres=100\n",
    "# brt_toprank=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated ML BRT and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def updateExistingDF(dfTmp, fileName, save=False):\n",
    "    if os.path.exists(fileName):\n",
    "        dfTmp = pd.concat([dfTmp, pd.read_csv(fileName)])\n",
    "        if 'params' in dfTmp.columns:\n",
    "            dfTmp[\"params\"] = dfTmp[\"params\"].iloc[0].__str__()\n",
    "        dfTmp = dfTmp.drop_duplicates(\n",
    "             subset=[x for x in dfTmp.columns if x != \"param_clf\" and x!='date' and 'split' not in x and '_time' not in x and 'rank_' not in x and 'std' not in x]\n",
    "        )\n",
    "    if save:\n",
    "        dfTmp.to_csv(fileName, index=False)\n",
    "\n",
    "    return dfTmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "896b989c08a64bf6b80ec45c09e01365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DataSet Main Outer Loop:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f924c1d2922140cfa3c7347122b85ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Boruta MD Loop:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde1e148370341aeaa825cfdfcd302d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Boruta MD Loop:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38964effe11c4103b0eac681f004124c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Boruta MD Loop:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1786c73e632848b78f2b71cd9cd93d5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Boruta MD Loop:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60b0bc87ed564c3491d3a5188b01fdc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Boruta MD Loop:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b5b94800ca4493caf35cfcfd6e17174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Boruta MD Loop:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d18547ce774323aaeae74d69fe559f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Boruta MD Loop:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45211f4a9ec24cd987823d8ec2199718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Boruta MD Loop:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lRunDataFrames = []\n",
    "for dataName in tqdm(lDataNames,desc='DataSet Main Outer Loop'):\n",
    "\n",
    "    df_tr = load_dataset_to_df(f\"{dataDir}{dataName}_Train.arrow\", verbose=True)\n",
    "    df_ts = load_dataset_to_df(f\"{dataDir}{dataName}_Test.arrow\", verbose=True)\n",
    "    df_h = load_dataset_to_df(f\"{dataDir}{dataName}_Holdout.arrow\", verbose=True)\n",
    "    df_full = pd.concat([df_tr,df_ts,df_h])\n",
    "\n",
    "    lColDrop = [\"__index_level_0__\", \"LC_STATUS_SITE\",'SITE']\n",
    "\n",
    "    for df in [df_tr,df_ts,df_h,df_full]:\n",
    "        df.drop(df[df[\"LC_STATUS\"] == 2].index, inplace=True)  # drop HC\n",
    "        for c in lColDrop:\n",
    "            if c in df.columns:\n",
    "                df.drop(columns=[c],inplace=True)\n",
    "        ##Depreciated below based on doing this in the splice data\n",
    "        # df[\"LC_STATUS\"] = df[\"LC_STATUS\"].apply(\n",
    "        #     lambda x: 1 if x == \"LC_POS\" else 0\n",
    "        # )  # Convert to 0==LCNeg, 1==LCPos\n",
    "        # df.drop(columns=lColDrop, inplace=True)  # drop unneeded columns\n",
    "\n",
    "    saveDir = MPutils.get_saving_dir(\n",
    "        f\"OUTPUT/MP/05-classifiers/DataV3/{dataName}/\"\n",
    "    )\n",
    "\n",
    "    ## HOLDOUT SET ONLY\n",
    "    x_h, y_h = getXY(df_h)\n",
    "\n",
    "    dfRHold = classify_MP(\n",
    "        X=x_h,\n",
    "        y=y_h,\n",
    "        lScorers=lScorersBinary,\n",
    "        lClassifiers=lClassifiers,\n",
    "        lTrees=lTrees,\n",
    "        lMD=lMD,\n",
    "        lCV=lCV,\n",
    "    )\n",
    "    dfRHold[\"Title\"] = f\"{dataName}_Holdout\"\n",
    "    dfRHold['RunType']='Holdout'\n",
    "\n",
    "    dfRHold[\"MainDataset\"] = dataName\n",
    "    dfRHold[\"date\"] = datetime.today()\n",
    "\n",
    "    holdFile = f\"{saveDir}CA_{dataName}_Holdout.csv\"\n",
    "    dfRHold = updateExistingDF(dfRHold, holdFile, save=True)\n",
    "\n",
    "    ## Full SET ONLY\n",
    "    x_F, y_F = getXY(df_full)\n",
    "\n",
    "    dfRFull = classify_MP(\n",
    "        X=x_F,\n",
    "        y=y_F,\n",
    "        lScorers=lScorersBinary,\n",
    "        lClassifiers=lClassifiers,\n",
    "        lTrees=lTrees,\n",
    "        lMD=lMD,\n",
    "        lCV=lCV,\n",
    "    )\n",
    "    dfRFull[\"Title\"] = f\"{dataName}_Full\"\n",
    "    dfRFull[\"RunType\"] = \"Full\"\n",
    "    dfRFull[\"MainDataset\"] = dataName\n",
    "    dfRFull[\"date\"] = datetime.today()\n",
    "\n",
    "    fulldataFile= f\"{saveDir}CA_{dataName}_Full.csv\"\n",
    "    dfRFull = updateExistingDF(dfRFull, fulldataFile, save=True)\n",
    "\n",
    "    ## BORUTA Feature Selection\n",
    "\n",
    "    x_Tr, y_Tr = getXY(df_tr)\n",
    "    lBrtResults = []\n",
    "    for boruta_md in tqdm(lBrt_MD[:],desc='Boruta MD Loop'):\n",
    "        # run brouta = get true and top feat\n",
    "        trueFeat, topFeat = boruta_fs(\n",
    "            X=x_Tr.values,\n",
    "            y=y_Tr,\n",
    "            feat_list=x_Tr.columns,\n",
    "            trees=brt_trees,\n",
    "            ittr=brt_iter,\n",
    "            threshold=brt_thres,\n",
    "            top_rank=brt_toprank,\n",
    "            verbose=0,\n",
    "            model=RandomForestClassifier(\n",
    "                n_jobs=-1, class_weight=\"balanced\", max_depth=boruta_md, random_state=42\n",
    "            ),\n",
    "            fileName=f\"{saveDir}FS_{dataName}_Boruta_T{brt_trees}_itrr{brt_iter}_th{brt_thres}_topR{brt_toprank}_MD{boruta_md}.csv\",\n",
    "        )\n",
    "\n",
    "        ## Test Brouta Features\n",
    "        x_TsMain, y_Ts = getXY(df_ts)\n",
    "\n",
    "        x_Ts_True = x_TsMain[trueFeat]\n",
    "        x_Ts_Top = x_TsMain[topFeat]\n",
    "\n",
    "        # True Feat\n",
    "        if len(trueFeat) > 0:\n",
    "            dfR_True = classify_MP(\n",
    "                X=x_Ts_True,\n",
    "                y=y_Ts,\n",
    "                lScorers=lScorersBinary,\n",
    "                lClassifiers=lClassifiers,\n",
    "                lTrees=lTrees,\n",
    "                lMD=lMD,\n",
    "                lCV=lCV,\n",
    "            )\n",
    "            dfR_True[\"Title\"] = f\"{dataName}_Boruta_True\"\n",
    "            dfR_True[\"brt_md\"] = boruta_md\n",
    "            dfR_True['brt_nTrue'] = len(trueFeat)\n",
    "            dfR_True['brt_nTop'] = len(topFeat)\n",
    "            dfR_True[\"RunType\"] = \"Boruta_True\"\n",
    "            lBrtResults.append(dfR_True)\n",
    "\n",
    "        # Top Feat\n",
    "        if len(topFeat) > 0:\n",
    "            dfR_Top = classify_MP(\n",
    "                X=x_Ts_Top,\n",
    "                y=y_Ts,\n",
    "                lScorers=lScorersBinary,\n",
    "                lClassifiers=lClassifiers,\n",
    "                lTrees=lTrees,\n",
    "                lMD=lMD,\n",
    "                lCV=lCV,\n",
    "            )\n",
    "            dfR_Top[\"Title\"] = f\"{dataName}_Boruta_Top\"\n",
    "\n",
    "            dfR_Top[\"brt_md\"] = boruta_md\n",
    "            dfR_Top['brt_nTrue'] = len(trueFeat)\n",
    "            dfR_Top[\"brt_nTop\"] = len(topFeat)\n",
    "            dfR_Top[\"RunType\"] = \"Boruta_Top\"\n",
    "            lBrtResults.append(dfR_Top)\n",
    "\n",
    "    dfCLFRun = pd.concat([dfRHold, dfRFull]+lBrtResults)\n",
    "\n",
    "    dfCLFRun[\"MainDataset\"] = dataName\n",
    "    dfCLFRun[\"date\"] = datetime.today()\n",
    "    dfCLFRun[\"brt_params\"] = (\n",
    "        f\"T{brt_trees}_itrr{brt_iter}_th{brt_thres}_topR{brt_toprank}\"\n",
    "    )\n",
    "\n",
    "    clfFile = f\"{saveDir}CLFRun_{dataName}_Results.csv\"\n",
    "\n",
    "    dfCLFRun = updateExistingDF(dfCLFRun,clfFile,save=False)\n",
    "    dfCLFRun = MPutils.reorder_columns(dfCLFRun, [\"MainDataset\", \"Title\", \"date\",'brt_nTrue','brt_nTop'])\n",
    "    dfCLFRun.to_csv(clfFile, index=False)\n",
    "    \n",
    "    # lRunDataFrames.append(dfCLFRun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Archived --- April 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfCombRes = pd.concat(lRunDataFrames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfCombRes[\"classifier\"] = dfCombRes[\"param_clf\"].apply(lambda x: x.__str__().split(\"(\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lColFirst = [\n",
    "#     \"MainDataset\",\n",
    "#     \"Title\",\n",
    "#     # \"date\",\n",
    "#     # \"classifier\",\n",
    "#     'RunType',\n",
    "#     \"cv\",\n",
    "#     # \"brt_nTrue\",\n",
    "#     # \"brt_nTop\",\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfCombRes = MPutils.reorder_columns(dfCombRes, lColFirst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfCombRes.to_csv('OUTPUT/MP/05-classifiers/DataV3/CLFRunCombined.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lColsSel = lColFirst + [\n",
    "#     x\n",
    "#     # for x in dfCombRes\n",
    "#     for x in dfRHold\n",
    "#     if (x.startswith(\"mean_test\") or x.startswith(\"param_\") or x.startswith(\"brt_\"))\n",
    "#     and  x not in lColFirst\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfCombRes[lColsSel].to_csv(\n",
    "#     \"OUTPUT/MP/05-classifiers/DataV3/CLFRunCombined_SelCol.csv\", index=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holdoutset - validation testing - Boruta Tested Best Feature + Sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalfeat = 'FS_dfcmpltPreLC3_Boruta_T1000_itrr500_th100_topR5_MD3'\n",
    "valSelTests = {\n",
    "    \"dfcmpltPreLC3\":[\n",
    "        globalfeat\n",
    "    ],\n",
    "    \"dfcmpltPreLC3_SITE1\":[\n",
    "        globalfeat,\n",
    "        'FS_dfcmpltPreLC3_SITE1_Boruta_T1000_itrr500_th100_topR5_MD5'\n",
    "    ],\n",
    "    \"dfcmpltPreLC3_SITE2\":[\n",
    "        globalfeat,\n",
    "        'FS_dfcmpltPreLC3_SITE2_Boruta_T1000_itrr500_th100_topR5_MD3'\n",
    "    ],\n",
    "    \"dfcmpltPreLC3_SITE3\":[\n",
    "        globalfeat,\n",
    "        'FS_dfcmpltPreLC3_SITE3_Boruta_T1000_itrr500_th100_topR5_MD3'\n",
    "    ],\n",
    "    \"dfcmpltPreLC3_SITE4\":[\n",
    "        globalfeat,\n",
    "        'FS_dfcmpltPreLC3_SITE4_Boruta_T1000_itrr500_th100_topR5_MD3'\n",
    "    ],\n",
    "    \"dfcmpltPreLC3_SITE5\":[\n",
    "        globalfeat,\n",
    "        'FS_dfcmpltPreLC3_SITE5_Boruta_T1000_itrr500_th100_topR5_MD3'\n",
    "    ],\n",
    "    \"dfcmpltPreLC3_SITE6\":[\n",
    "        globalfeat,\n",
    "        'FS_dfcmpltPreLC3_SITE6_Boruta_T1000_itrr500_th100_topR5_MD3'\n",
    "    ],\n",
    "    \"dfcmpltPreLC3_SITE7\":[\n",
    "        globalfeat,\n",
    "        'FS_dfcmpltPreLC3_SITE7_Boruta_T1000_itrr500_th100_topR5_MD3'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lDT_7 = MPutils.getTrueFeatList(\n",
    "# #     \"OUTPUT/MP/05-classifiers/DataV2/DT/FS_DT_Boruta_T1000_itrr500_th100_topR5_MD7.csv\"\n",
    "\n",
    "\n",
    "# lCmplt = MPutils.getTrueFeatList(\n",
    "#     \"OUTPUT/MP/05-classifiers/DataV3/dfcmplt/FS_dfcmplt_Boruta_T1000_itrr500_th100_topR5_MD7.csv\"\n",
    "# )\n",
    "\n",
    "\n",
    "# lColFS = lCmplt\n",
    "# # dataName = \"T81\"\n",
    "# selFeatName = \"FS_dfcmplt_Boruta_T1000_itrr500_th100_topR5_MD7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../Data/DataV3/TTS/'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ee1058280848beb5d05ebd3273195b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DataSet Main Outer Loop:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "lRunDataFrames = []\n",
    "for selData in tqdm(valSelTests.keys(),desc='DataSet Main Outer Loop'):\n",
    "    for selFeatName in valSelTests[selData]:\n",
    "\n",
    "        df_h = load_dataset_to_df(f\"{dataDir}{selData}_Holdout.arrow\", verbose=True)\n",
    "\n",
    "        lColDrop = [\"__index_level_0__\", \"LC_STATUS_SITE\",'SITE']\n",
    "\n",
    "        df_h.drop(df_h[df_h[\"LC_STATUS\"] == 2].index, inplace=True)  # drop HC\n",
    "\n",
    "        # df_h[\"LC_STATUS\"] = df_h[\"LC_STATUS\"].apply(\n",
    "        #     lambda x: 1 if x == \"LC_POS\" else 0\n",
    "        # )  # Convert to 0==LCNeg, 1==LCPos\n",
    "\n",
    "        for c in lColDrop:\n",
    "            if c in df_h.columns:\n",
    "                df_h.drop(columns=[c], inplace=True)\n",
    "        # df_h.drop(columns=lColDrop, inplace=True)  # drop unneeded columns\n",
    "\n",
    "        saveDir = MPutils.get_saving_dir(\n",
    "            f\"OUTPUT/MP/05-classifiers/DataV3/{selData}/\"\n",
    "        )\n",
    "\n",
    "        featDir= selFeatName.replace('FS_','').split('_Boruta')[0]\n",
    "        lColFS = MPutils.getTrueFeatList(f\"OUTPUT/MP/05-classifiers/DataV3/{featDir}/{selFeatName}.csv\")\n",
    "        \n",
    "        ## HOLDOUT SET ONLY\n",
    "        x_h, y_h = getXY(df_h)\n",
    "        x_h = x_h[lColFS]\n",
    "\n",
    "        dfRHold = classify_MP(\n",
    "            X=x_h,\n",
    "            y=y_h,\n",
    "            lScorers=lScorersBinary,\n",
    "            lClassifiers=lClassifiers,\n",
    "            lTrees=lTrees,\n",
    "            lMD=lMD,\n",
    "            lCV=lCV,\n",
    "        )\n",
    "        dfRHold[\"Title\"] = f\"{selData}_HoldoutVal\"\n",
    "        dfRHold['RunType']='HoldoutVal'\n",
    "        dfRHold[\"FeatureSet\"] = selFeatName\n",
    "        dfRHold['date']=datetime.today()\n",
    "        dfRHold[\"classifier\"] = dfRHold[\"param_clf\"].apply(lambda x: x.__str__().split(\"(\")[0])\n",
    "        dfRHold[\"MainDataset\"] = selData\n",
    "\n",
    "        lColFirst = [\n",
    "            \"MainDataset\",\n",
    "            \"Title\",\n",
    "            'FeatureSet',\n",
    "            \"date\",\n",
    "            \"classifier\",\n",
    "            \"RunType\",\n",
    "            \"cv\",\n",
    "        ]\n",
    "        dfRHold = MPutils.reorder_columns(dfRHold, lColFirst)\n",
    "\n",
    "        ## Export\n",
    "        dfRHold.to_csv(f\"{saveDir}Val_{selData}_HoldoutVal_{selFeatName}.csv\", index=False)\n",
    "\n",
    "        ## Select Columns\n",
    "        lColsSel = lColFirst + [\n",
    "            x\n",
    "            for x in dfRHold\n",
    "            if (x.startswith(\"mean_test\") or x.startswith(\"param_\") or x.startswith(\"brt_\"))\n",
    "            and x not in lColFirst\n",
    "        ]\n",
    "\n",
    "        dfRHold[lColsSel].to_csv(\n",
    "            f\"{saveDir}Val_{selData}_HoldoutVal_{selFeatName}_SelCol.csv\",\n",
    "            index=False,\n",
    "        )\n",
    "\n",
    "    # lRunDataFrames.append(dfRHold)\n",
    "\n",
    "        ### Feature Importance\n",
    "\n",
    "        clf = RandomForestClassifier(n_estimators=1000, max_depth=10, random_state=42)\n",
    "        clf.fit(x_h, y_h)\n",
    "        feature_importances = clf.feature_importances_\n",
    "        feature_importances = pd.Series(feature_importances, index=x_h.columns).sort_values(\n",
    "            ascending=False\n",
    "        )\n",
    "\n",
    "        dfFeatureImp = pd.DataFrame(feature_importances).reset_index()\n",
    "        dfFeatureImp.columns = [\"Feature\", \"Importance\"]\n",
    "        dfFeatureImp[\"Importance\"] = dfFeatureImp[\"Importance\"].round(4)\n",
    "        dfFeatureImp[\"Rank\"] = dfFeatureImp.rank(ascending=False)[\"Importance\"].astype(int)\n",
    "        dfFeatureImp = dfFeatureImp[[\"Rank\", \"Feature\", \"Importance\"]]\n",
    "\n",
    "        dfFeatureImp.to_csv(\n",
    "            f\"{saveDir}FR_{selData}_HoldoutVal_{selFeatName}.csv\", index=False\n",
    "        )\n",
    "\n",
    "\n",
    "# dfCombRes = pd.concat(lRunDataFrames)\n",
    "\n",
    "# dfCombRes = MPutils.reorder_columns(dfCombRes, lColFirst)\n",
    "\n",
    "# dfCombRes.to_csv(\n",
    "#     f\"OUTPUT/MP/05-classifiers/DataV3/CLFHoldoutValRunCombined_{selFeatName}.csv\",\n",
    "#     index=False,\n",
    "# )\n",
    "# lColsSel = lColFirst + [\n",
    "#     x\n",
    "#     for x in dfCombRes\n",
    "#     if (x.startswith(\"mean_test\") or x.startswith(\"param_\") or x.startswith(\"brt_\"))\n",
    "#     and x not in lColFirst\n",
    "# ]\n",
    "# dfCombRes[lColsSel].to_csv(\n",
    "#    f\"OUTPUT/MP/05-classifiers/DataV3/CLFHoldoutValRunCombined_{selFeatName}_selCol.csv\",\n",
    "#     index=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depreciated - May 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_h = load_dataset_to_df(f\"{dataDir}{dataName}_Holdout.arrow\", verbose=True)\n",
    "\n",
    "# lColDrop = [\"__index_level_0__\", \"LC_STATUS_SITE\",'SITE']\n",
    "\n",
    "\n",
    "# df_h.drop(df_h[df_h[\"LC_STATUS\"] == 2].index, inplace=True)  # drop HC\n",
    "\n",
    "# # df_h[\"LC_STATUS\"] = df_h[\"LC_STATUS\"].apply(\n",
    "# #     lambda x: 1 if x == \"LC_POS\" else 0\n",
    "# # )  # Convert to 0==LCNeg, 1==LCPos\n",
    "# df_h.drop(columns=lColDrop, inplace=True)  # drop unneeded columns\n",
    "\n",
    "# saveDir = MPutils.get_saving_dir(\n",
    "#     f\"OUTPUT/MP/05-classifiers/DataV3/{dataName}/\"\n",
    "# )\n",
    "\n",
    "# ## HOLDOUT SET ONLY\n",
    "# x_h, y_h = getXY(df_h)\n",
    "# x_h = x_h[lColFS]\n",
    "\n",
    "# dfRHold = classify_MP(\n",
    "#     X=x_h,\n",
    "#     y=y_h,\n",
    "#     lScorers=lScorersBinary,\n",
    "#     lClassifiers=lClassifiers,\n",
    "#     lTrees=lTrees,\n",
    "#     lMD=lMD,\n",
    "#     lCV=lCV,\n",
    "# )\n",
    "# dfRHold[\"Title\"] = f\"{dataName}_HoldoutVal\"\n",
    "# dfRHold['RunType']='HoldoutVal'\n",
    "# dfRHold[\"FeatureSet\"] = selFeatName\n",
    "# dfRHold['date']=datetime.today()\n",
    "# dfRHold[\"classifier\"] = dfRHold[\"param_clf\"].apply(lambda x: x.__str__().split(\"(\")[0])\n",
    "# dfRHold[\"MainDataset\"] = dataName\n",
    "\n",
    "# lColFirst = [\n",
    "#     \"MainDataset\",\n",
    "#     \"Title\",\n",
    "#     \"date\",\n",
    "#     \"classifier\",\n",
    "#     \"RunType\",\n",
    "#     \"cv\",\n",
    "# ]\n",
    "# dfRHold = MPutils.reorder_columns(dfRHold, lColFirst)\n",
    "\n",
    "# dfRHold.to_csv(f\"{saveDir}Val_{dataName}_HoldoutVal_{selFeatName}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfCombRes = pd.concat(lRunDataFrames)\n",
    "# dfCombRes[\"classifier\"] = dfCombRes[\"param_clf\"].apply(\n",
    "#     lambda x: x.__str__().split(\"(\")[0]\n",
    "# )\n",
    "# lColFirst = [\n",
    "#     \"MainDataset\",\n",
    "#     \"Title\",\n",
    "#     \"date\",\n",
    "#     \"classifier\",\n",
    "#     \"RunType\",\n",
    "#     \"cv\",\n",
    "#     \"brt_nTrue\",\n",
    "#     \"brt_nTop\",\n",
    "# ]\n",
    "# dfCombRes = MPutils.reorder_columns(dfCombRes, lColFirst)\n",
    "# dfCombRes.to_csv(\"OUTPUT/MP/05-classifiers/DataV3/CLFRunCombined.csv\", index=False)\n",
    "# lColsSel = lColFirst + [\n",
    "#     x\n",
    "#     for x in dfCombRes\n",
    "#     if (x.startswith(\"mean_test\") or x.startswith(\"param_\") or x.startswith(\"brt_\"))\n",
    "#     and x not in lColFirst\n",
    "# ]\n",
    "# dfCombRes[lColsSel].to_csv(\n",
    "#     \"OUTPUT/MP/05-classifiers/DataV3/CLFRunCombined_SelCol.csv\", index=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lColsSel = lColFirst + [\n",
    "#     x\n",
    "#     for x in dfRHold\n",
    "#     if (x.startswith(\"mean_test\") or x.startswith(\"param_\") or x.startswith(\"brt_\"))\n",
    "#     and x not in lColFirst\n",
    "# ]\n",
    "# dfRHold[lColsSel].to_csv(f\"{saveDir}Val_{dataName}_HoldoutVal_{selFeatName}_SelCol.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance of Best Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=1000,max_depth=10,random_state=42)\n",
    "clf.fit(x_h,y_h)\n",
    "feature_importances = clf.feature_importances_\n",
    "feature_importances = pd.Series(feature_importances, index=x_h.columns).sort_values(\n",
    "    ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFeatureImp = pd.DataFrame(feature_importances).reset_index()\n",
    "dfFeatureImp.columns = ['Feature','Importance']\n",
    "dfFeatureImp[\"Importance\"] = dfFeatureImp[\"Importance\"].round(4)\n",
    "dfFeatureImp[\"Rank\"] = dfFeatureImp.rank(ascending=False)[\"Importance\"].astype(int)\n",
    "dfFeatureImp = dfFeatureImp[['Rank','Feature','Importance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>SYMPT-fatigue___2</td>\n",
       "      <td>0.2420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>SYMPT-shortness_of_breath_dyspne___2</td>\n",
       "      <td>0.1566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>SYMPT-loss_of_taste_lost_of_smel___2</td>\n",
       "      <td>0.0913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>SYMPT-cough___2</td>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>SYMPT-dizziness___2</td>\n",
       "      <td>0.0811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>SYMPT-joint_pain_arthralgia___2</td>\n",
       "      <td>0.0685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>SYMPT-headache___2</td>\n",
       "      <td>0.0533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>SYMPT-muscle_aches_myalgia___2</td>\n",
       "      <td>0.0475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>age</td>\n",
       "      <td>0.0324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>SYMPT-chest_pain___2</td>\n",
       "      <td>0.0274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>SYMPT-extremity_weakness_or_numb___2</td>\n",
       "      <td>0.0237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>SYMPT-nausea_vomiting___2</td>\n",
       "      <td>0.0101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>SYMPT-loss_of_appetite___2</td>\n",
       "      <td>0.0096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>SYMPT-abdominal_pain___2</td>\n",
       "      <td>0.0095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>SYMPT-leg_swelling_edema___2</td>\n",
       "      <td>0.0079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>SYMPT-cough___1</td>\n",
       "      <td>0.0068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>SYMPT-sore_throat___2</td>\n",
       "      <td>0.0065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>SYMPT-fatigue___1</td>\n",
       "      <td>0.0056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>SYMPT-sore_throat___1</td>\n",
       "      <td>0.0054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>SYMPT-confusion_altered_mental_s___2</td>\n",
       "      <td>0.0052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>SYMPT-diarrhea___2</td>\n",
       "      <td>0.0049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>SYMPT-dizziness___1</td>\n",
       "      <td>0.0047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>SYMPT-headache___1</td>\n",
       "      <td>0.0040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>SYMPT-fever_38_0oc___1</td>\n",
       "      <td>0.0038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>SYMPT-skin_rash___2</td>\n",
       "      <td>0.0034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>SYMPT-fever_38_0oc___2</td>\n",
       "      <td>0.0028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                               Feature  Importance\n",
       "0      1                     SYMPT-fatigue___2      0.2420\n",
       "1      2  SYMPT-shortness_of_breath_dyspne___2      0.1566\n",
       "2      3  SYMPT-loss_of_taste_lost_of_smel___2      0.0913\n",
       "3      4                       SYMPT-cough___2      0.0859\n",
       "4      5                   SYMPT-dizziness___2      0.0811\n",
       "5      6       SYMPT-joint_pain_arthralgia___2      0.0685\n",
       "6      7                    SYMPT-headache___2      0.0533\n",
       "7      8        SYMPT-muscle_aches_myalgia___2      0.0475\n",
       "8      9                                   age      0.0324\n",
       "9     10                  SYMPT-chest_pain___2      0.0274\n",
       "10    11  SYMPT-extremity_weakness_or_numb___2      0.0237\n",
       "11    12             SYMPT-nausea_vomiting___2      0.0101\n",
       "12    13            SYMPT-loss_of_appetite___2      0.0096\n",
       "13    14              SYMPT-abdominal_pain___2      0.0095\n",
       "14    15          SYMPT-leg_swelling_edema___2      0.0079\n",
       "15    16                       SYMPT-cough___1      0.0068\n",
       "16    17                 SYMPT-sore_throat___2      0.0065\n",
       "17    18                     SYMPT-fatigue___1      0.0056\n",
       "18    19                 SYMPT-sore_throat___1      0.0054\n",
       "19    20  SYMPT-confusion_altered_mental_s___2      0.0052\n",
       "20    21                    SYMPT-diarrhea___2      0.0049\n",
       "21    22                   SYMPT-dizziness___1      0.0047\n",
       "22    23                    SYMPT-headache___1      0.0040\n",
       "23    24                SYMPT-fever_38_0oc___1      0.0038\n",
       "24    25                   SYMPT-skin_rash___2      0.0034\n",
       "25    26                SYMPT-fever_38_0oc___2      0.0028"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfFeatureImp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFeatureImp.to_csv(f\"{saveDir}FR_{dataName}_HoldoutVal{selFeatName}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=1000, max_depth=None, random_state=42)\n",
    "cross_val_score(clf, x_h, y_h, cv=5, scoring=\"accuracy\").mean().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holdoutset - validation testing PER SITE - Boruta Tested Best Featuref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# site_name_dict = {\n",
    "#                   1: 'LDN',\n",
    "#                   2: 'MTL',\n",
    "#                   3: 'SAN',\n",
    "#                   4: 'RIO',\n",
    "#                   5: 'LUS',\n",
    "#                   6:'CA',\n",
    "#                   7:'NorthA'\n",
    "#                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lDT_7 = MPutils.getTrueFeatList(\n",
    "# #     \"OUTPUT/MP/05-classifiers/DataV2/DT/FS_DT_Boruta_T1000_itrr500_th100_topR5_MD7.csv\"\n",
    "# # )\n",
    "\n",
    "\n",
    "# # lColFS = lDT_7\n",
    "# # dataName = \"DT\"\n",
    "# # selFeatName = \"FS_DT_Boruta_T1000_itrr500_th100_topR5_MD7\"\n",
    "\n",
    "# # - DT BRT_MD7 True has the best test numbers with 96%.\n",
    "# # - BUT the DT dataset has basically no LUS patients…. thus is not a good representation of a “global cohort”\n",
    "# # - THUS we should probably use and report the T81 dataset\n",
    "\n",
    "# lR81_5 = MPutils.getTrueFeatList(\n",
    "#     \"OUTPUT/MP/05-classifiers/DataV2/T81/FS_T81_Boruta_T1000_itrr500_th100_topR5_MD5.csv\"\n",
    "# )\n",
    "\n",
    "\n",
    "# lColFS = lR81_5\n",
    "# dataName = \"T81\"\n",
    "# selFeatName = \"FS_T81_Boruta_T1000_itrr500_th100_topR5_MD5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lSiteRes = []\n",
    "# for i in tqdm(site_name_dict.keys()):\n",
    "#     df_h = load_dataset_to_df(f\"{dataDir}{dataName}_Holdout.arrow\", verbose=True)\n",
    "#     if i==7:\n",
    "#         df_h = df_h[df_h['SITE']<=3]\n",
    "#     elif i==6:\n",
    "#         df_h = df_h[df_h['SITE']<=2]\n",
    "#     else:\n",
    "#         df_h = df_h[df_h[\"SITE\"] ==i]\n",
    "\n",
    "#     lColDrop = [\"__index_level_0__\", \"LC_STATUS_SITE\",'SITE']\n",
    "\n",
    "#     df_h.drop(df_h[df_h[\"LC_STATUS\"] == \"HC\"].index, inplace=True)  # drop HC\n",
    "#     df_h[\"LC_STATUS\"] = df_h[\"LC_STATUS\"].apply(\n",
    "#         lambda x: 1 if x == \"LC_POS\" else 0\n",
    "#     )  # Convert to 0==LCNeg, 1==LCPos\n",
    "#     df_h.drop(columns=lColDrop, inplace=True)  # drop unneeded columns\n",
    "\n",
    "#     saveDir = MPutils.get_saving_dir(\n",
    "#         f\"OUTPUT/MP/05-classifiers/DataV2/{dataName}/SITE_{i}_{site_name_dict[i]}/\"\n",
    "#     )\n",
    "#     ## HOLDOUT SET ONLY\n",
    "#     x_h, y_h = getXY(df_h)\n",
    "#     x_h = x_h[lColFS]\n",
    "\n",
    "#     dfRHold = classify_MP(\n",
    "#         X=x_h,\n",
    "#         y=y_h,\n",
    "#         lScorers=lScorersBinary,\n",
    "#         lClassifiers=lClassifiers,\n",
    "#         lTrees=lTrees,\n",
    "#         lMD=lMD,\n",
    "#         lCV=lCV,\n",
    "#     )\n",
    "#     dfRHold[\"Title\"] = f\"{dataName}_HoldoutVal\"\n",
    "#     dfRHold[\"RunType\"] = \"HoldoutVal_Site\"\n",
    "#     dfRHold[\"Site\"] = site_name_dict[i]\n",
    "#     dfRHold[\"FeatureSet\"] = selFeatName\n",
    "#     dfRHold[\"date\"] = datetime.today()\n",
    "#     dfRHold[\"classifier\"] = dfRHold[\"param_clf\"].apply(lambda x: x.__str__().split(\"(\")[0])\n",
    "#     dfRHold[\"MainDataset\"] = dataName\n",
    "\n",
    "#     lColFirst = [\n",
    "#         \"date\",\n",
    "#         \"MainDataset\",\n",
    "#         \"Title\",\n",
    "#         \"RunType\",\n",
    "#         'Site',\n",
    "#         \"classifier\",\n",
    "#         \"cv\",\n",
    "#     ]\n",
    "#     dfRHold = MPutils.reorder_columns(dfRHold, lColFirst)\n",
    "\n",
    "#     dfRHold.to_csv(\n",
    "#         f\"{saveDir}Val_{dataName}_HoldoutVal_{selFeatName}_SITE{i}.csv\", index=False\n",
    "#     )\n",
    "\n",
    "#     lColsSel = lColFirst + [\n",
    "#         x\n",
    "#         for x in dfRHold\n",
    "#         if (x.startswith(\"mean_test\") or x.startswith(\"param_\") or x.startswith(\"brt_\"))\n",
    "#         and x not in lColFirst\n",
    "#     ]\n",
    "#     dfRHold[lColsSel].to_csv(\n",
    "#         f\"{saveDir}Val_{dataName}_HoldoutVal_{selFeatName}_SITE{i}_SelCol.csv\",\n",
    "#         index=False,\n",
    "#     )\n",
    "#     lSiteRes.append(dfRHold)\n",
    "\n",
    "#     ### Feature Importance\n",
    "\n",
    "#     clf = RandomForestClassifier(n_estimators=1000, max_depth=10, random_state=42)\n",
    "#     clf.fit(x_h, y_h)\n",
    "#     feature_importances = clf.feature_importances_\n",
    "#     feature_importances = pd.Series(feature_importances, index=x_h.columns).sort_values(\n",
    "#         ascending=False\n",
    "#     )\n",
    "\n",
    "#     dfFeatureImp = pd.DataFrame(feature_importances).reset_index()\n",
    "#     dfFeatureImp.columns = [\"Feature\", \"Importance\"]\n",
    "#     dfFeatureImp[\"Importance\"] = dfFeatureImp[\"Importance\"].round(4)\n",
    "#     dfFeatureImp[\"Rank\"] = dfFeatureImp.rank(ascending=False)[\"Importance\"].astype(int)\n",
    "#     dfFeatureImp = dfFeatureImp[[\"Rank\", \"Feature\", \"Importance\"]]\n",
    "\n",
    "#     dfFeatureImp.to_csv(\n",
    "#         f\"{saveDir}FR_{dataName}_HoldoutVal{selFeatName}_SITE{i}.csv\", index=False\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.concat(lSiteRes).to_csv('OUTPUT/MP/05-classifiers/DataV2/CLFRunCombined_Site.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.concat(lSiteRes)[lColsSel].to_csv(\n",
    "#     \"OUTPUT/MP/05-classifiers/DataV2/CLFRunCombined_Site_SelCol.csv\", index=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clust",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
