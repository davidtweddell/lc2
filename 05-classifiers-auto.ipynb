{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload magics\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datasets\n",
    "from project_modules.io import load_dataset_to_df\n",
    "from project_modules.classifcation import classify_MP,getXY, boruta_fs\n",
    "from project_modules.utils import MPutils\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import multiprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import cupy as cp\n",
    "from datetime import datetime\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# from project_modules.utils import get_logger\n",
    "# logger = get_logger(\"log-data-combine-split.log\")\n",
    "# # read the parameter file\n",
    "\n",
    "# from project_modules.utils import read_parameters\n",
    "# parms = read_parameters(\"/Users/david/projects/lc-project-data/project.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# input_path = Path(\"../lc-project-data\")\n",
    "# output_path = Path(\"../lc-project-data\")\n",
    "\n",
    "# for MP,\n",
    "# input_path = Path(\"../Data/DataV3\")\n",
    "# output_path = Path(\"OUTPUT/MP/05-classifiers/DataV3/\")\n",
    "\n",
    "#DataV4 - 2024-10-09 - Dropped patients with missing vax data\n",
    "input_path = Path(\"../Data/DataV4\")\n",
    "output_path = Path(\"OUTPUT/MP/05-classifiers/DataV4/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lScorersBinary = [\n",
    "    \"accuracy\",\n",
    "    \"balanced_accuracy\",\n",
    "    \"roc_auc\",\n",
    "    \"f1\",\n",
    "    \"recall\",\n",
    "    \"sensitivity\",\n",
    "    \"specificity\",\n",
    "    \"precision\",\n",
    "    # \"average_precision\",\n",
    "    \"NPV\",\n",
    "    \"PPV\",\n",
    "    # \"neg_mean_squared_error\",\n",
    "]\n",
    "lResCol = [\n",
    "    \"Title\",\n",
    "    \"cv\",\n",
    "    \"param_clf\",\n",
    "    \"param_clf__max_depth\",\n",
    "    \"param_clf__n_estimators\",\n",
    "    \"param_clf__random_state\",\n",
    "    # \"param_clf__max_iter\",\n",
    "    \"mean_test_accuracy\",\n",
    "    \"mean_test_balanced_accuracy\",\n",
    "    \"mean_test_roc_auc\",\n",
    "    \"mean_test_f1\",\n",
    "    \"mean_test_recall\",\n",
    "    \"mean_test_sensitivity\",\n",
    "    \"mean_test_specificity\",\n",
    "    \"mean_test_precision\",\n",
    "    \"mean_test_NPV\",\n",
    "    \"mean_test_PPV\",\n",
    "]\n",
    "\n",
    "lPrettyCols = [\n",
    "    \"MainDataset\",\n",
    "    \"RunType\",\n",
    "    \"classifier\",\n",
    "    \"brt_nTrue\",\n",
    "    \"brt_nTop\",\n",
    "    \"accuracy\",\n",
    "    \"balanced_accuracy\",\n",
    "    \"roc_auc\",\n",
    "    \"f1\",\n",
    "    \"recall\",\n",
    "    \"sensitivity\",\n",
    "    \"specificity\",\n",
    "    \"precision\",\n",
    "    \"NPV\",\n",
    "    \"PPV\",\n",
    "    \"brt_md\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lDataNames = ['T81','T85','DT']\n",
    "\n",
    "\n",
    "lDataNames = [\n",
    "    # \"dfcmplt\", # Done\n",
    "    # \"dfcmplt_SITE1\", # Done\n",
    "    # \"dfcmplt_SITE2\", # Done\n",
    "    # \"dfcmplt_SITE3\", # Done\n",
    "    # \"dfcmplt_SITE4\", # Done\n",
    "    # \"dfcmplt_SITE5\",  # LEFT\n",
    "    # \"dfcmplt_SITE6\",  # LEFT\n",
    "    # \"dfcmplt_SITE7\",  # LEFT\n",
    "    # \"dfcmpltPreLC\",  # Done\n",
    "    # \"dfcmpltPreLC_SITE1\", # Done\n",
    "    # \"dfcmpltPreLC_SITE2\", # Done\n",
    "    # \"dfcmpltPreLC_SITE3\", # Done\n",
    "    # \"dfcmpltPreLC_SITE4\", # Done\n",
    "    # \"dfcmpltPreLC_SITE5\",  # Done\n",
    "    # \"dfcmpltPreLC_SITE6\",  # Done\n",
    "    # \"dfcmpltPreLC_SITE7\",  # Done\n",
    "    # \"dfcmpltPreLC2\",  # Done\n",
    "    # \"dfcmpltPreLC2_SITE1\", # Done\n",
    "    # \"dfcmpltPreLC2_SITE2\", # Done\n",
    "    # \"dfcmpltPreLC2_SITE3\", # Done\n",
    "    # \"dfcmpltPreLC2_SITE4\", # Done\n",
    "    # \"dfcmpltPreLC2_SITE5\",  # Done\n",
    "    # \"dfcmpltPreLC2_SITE6\",  # Done\n",
    "    # \"dfcmpltPreLC2_SITE7\",  # Done\n",
    "    # \"dfcmpltPreLC3\",  # Done\n",
    "    # \"dfcmpltPreLC3_SITE1\", # Done\n",
    "    # \"dfcmpltPreLC3_SITE2\", # Done\n",
    "    # \"dfcmpltPreLC3_SITE3\", # Done\n",
    "    # \"dfcmpltPreLC3_SITE4\", # Done\n",
    "    # \"dfcmpltPreLC3_SITE5\",  # Done\n",
    "    # \"dfcmpltPreLC3_SITE6\",  # Done\n",
    "    # \"dfcmpltPreLC3_SITE7\",  # Done\n",
    "    \"dfcmpltPreLC4\",  # Done\n",
    "    # \"dfcmpltPreLC4_SITE1\", # \n",
    "    # \"dfcmpltPreLC4_SITE2\", # \n",
    "    # \"dfcmpltPreLC4_SITE3\", # \n",
    "    # \"dfcmpltPreLC4_SITE4\", # \n",
    "    # \"dfcmpltPreLC4_SITE5\",  # \n",
    "    # \"dfcmpltPreLC4_SITE6\",  # \n",
    "    # \"dfcmpltPreLC4_SITE7\",  # \n",
    "]\n",
    "dataDir = \"../Data/DataV4/TTS/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saveDir = MPutils.get_saving_dir(f\"OUTPUT/MP/05-classifiers/DataV2/{dataName}/\")\n",
    "\n",
    "\n",
    "lClassifiers = [\"RF\", \"LogR\",'XGBcpu'] # different classifiers #NOTE - XGBcpu is faster than XGBcuda for some reason?\n",
    "lCV = [5] # different cross-validation splits\n",
    "lTrees=[100,1000] #num trees\n",
    "lMD=[3,6,10,15, None] #max depth\n",
    "\n",
    "lBrt_MD = [3, 5, 7]\n",
    "brt_trees = 1000\n",
    "brt_iter = 500\n",
    "brt_thres = 100\n",
    "brt_toprank = 5\n",
    "\n",
    "\n",
    "# FIXME - BELOW CODE FOR TESTING PURPOSES\n",
    "# dataName = 'dfcmplt'\n",
    "# lClassifiers = [\n",
    "#     \"RF\",\n",
    "#     \"LogR\",\n",
    "#     \"XGBcpu\",\n",
    "# ]  # different classifiers #NOTE - XGBcpu is faster than XGBcuda for some reason?\n",
    "# lCV = [5]  # different cross-validation splits\n",
    "# lTrees = [10]  # num trees\n",
    "# lMD = [3]  # max depth\n",
    "\n",
    "# lBrt_MD = [4]\n",
    "# brt_trees=12\n",
    "# brt_iter = 10\n",
    "# brt_thres=100\n",
    "# brt_toprank=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated ML BRT and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def updateExistingDF(dfTmp, fileName, save=False):\n",
    "    if os.path.exists(fileName):\n",
    "        dfTmp = pd.concat([dfTmp, pd.read_csv(fileName)])\n",
    "        if 'params' in dfTmp.columns:\n",
    "            dfTmp[\"params\"] = dfTmp[\"params\"].iloc[0].__str__()\n",
    "        dfTmp = dfTmp.drop_duplicates(\n",
    "             subset=[x for x in dfTmp.columns if x != \"param_clf\" and x!='date' and 'split' not in x and '_time' not in x and 'rank_' not in x and 'std' not in x]\n",
    "        )\n",
    "    if save:\n",
    "        dfTmp.to_csv(fileName, index=False)\n",
    "\n",
    "    return dfTmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52441e8b460840e28028014a95cafcc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DataSet Main Outer Loop:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aad5aa2442034b508186e53371886e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Boruta MD Loop:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 78\u001b[0m\n\u001b[1;32m     75\u001b[0m lBrtResults \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m boruta_md \u001b[38;5;129;01min\u001b[39;00m tqdm(lBrt_MD[:],desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBoruta MD Loop\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;66;03m# run brouta = get true and top feat\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m     trueFeat, topFeat \u001b[38;5;241m=\u001b[39m \u001b[43mboruta_fs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_Tr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_Tr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeat_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_Tr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrees\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbrt_trees\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mittr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbrt_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbrt_thres\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbrt_toprank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRandomForestClassifier\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbalanced\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mboruta_md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\n\u001b[1;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfileName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msaveDir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43mFS_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdataName\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_Boruta_T\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbrt_trees\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_itrr\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbrt_iter\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_th\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbrt_thres\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_topR\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbrt_toprank\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_MD\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mboruta_md\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;66;03m## Test Brouta Features\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     x_TsMain, y_Ts \u001b[38;5;241m=\u001b[39m getXY(df_ts)\n",
      "File \u001b[0;32m~/_Research/r_2024_phd_01_fraser_lcoptimize_multicenter/davidgit/project_modules/classifcation/_classify.py:273\u001b[0m, in \u001b[0;36mboruta_fs\u001b[0;34m(X, y, feat_list, trees, ittr, threshold, top_rank, model, fileName, verbose, random_state)\u001b[0m\n\u001b[1;32m    263\u001b[0m feat_selector \u001b[38;5;241m=\u001b[39m BorutaPy(\n\u001b[1;32m    264\u001b[0m     model,\n\u001b[1;32m    265\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39mtrees,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    269\u001b[0m     random_state\u001b[38;5;241m=\u001b[39mrandom_state,\n\u001b[1;32m    270\u001b[0m )  \u001b[38;5;66;03m# , verbose=1\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# find all relevant features\u001b[39;00m\n\u001b[0;32m--> 273\u001b[0m \u001b[43mfeat_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;66;03m# check selected features\u001b[39;00m\n\u001b[1;32m    276\u001b[0m sup \u001b[38;5;241m=\u001b[39m feat_selector\u001b[38;5;241m.\u001b[39msupport_\n",
      "File \u001b[0;32m~/anaconda3/envs/R2024_LCO/lib/python3.11/site-packages/boruta/boruta_py.py:201\u001b[0m, in \u001b[0;36mBorutaPy.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m    189\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m    Fits the Boruta feature selection with the provided estimator.\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;124;03m        The target values.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/R2024_LCO/lib/python3.11/site-packages/boruta/boruta_py.py:260\u001b[0m, in \u001b[0;36mBorutaPy._fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    255\u001b[0m _iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# holds the decision about each feature:\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# 0  - default state = tentative in original code\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# 1  - accepted in original code\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# -1 - rejected in original code\u001b[39;00m\n\u001b[0;32m--> 260\u001b[0m dec_reg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(n_feat, dtype\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint\u001b[49m)\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# counts how many times a given feature was more important than\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# the best of the shadow features\u001b[39;00m\n\u001b[1;32m    263\u001b[0m hit_reg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(n_feat, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint)\n",
      "File \u001b[0;32m~/anaconda3/envs/R2024_LCO/lib/python3.11/site-packages/numpy/__init__.py:324\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    319\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtesting\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "lRunDataFrames = []\n",
    "for dataName in tqdm(lDataNames,desc='DataSet Main Outer Loop'):\n",
    "\n",
    "    df_tr = load_dataset_to_df(f\"{dataDir}{dataName}_Train.arrow\", verbose=True)\n",
    "    df_ts = load_dataset_to_df(f\"{dataDir}{dataName}_Test.arrow\", verbose=True)\n",
    "    df_h = load_dataset_to_df(f\"{dataDir}{dataName}_Holdout.arrow\", verbose=True)\n",
    "    df_full = pd.concat([df_tr,df_ts,df_h])\n",
    "\n",
    "    lColDrop = [\"__index_level_0__\", \"LC_STATUS_SITE\",'SITE']\n",
    "\n",
    "    for df in [df_tr,df_ts,df_h,df_full]:\n",
    "        df.drop(df[df[\"LC_STATUS\"] == 2].index, inplace=True)  # drop HC\n",
    "        for c in lColDrop:\n",
    "            if c in df.columns:\n",
    "                df.drop(columns=[c],inplace=True)\n",
    "        ##Depreciated below based on doing this in the splice data\n",
    "        # df[\"LC_STATUS\"] = df[\"LC_STATUS\"].apply(\n",
    "        #     lambda x: 1 if x == \"LC_POS\" else 0\n",
    "        # )  # Convert to 0==LCNeg, 1==LCPos\n",
    "        # df.drop(columns=lColDrop, inplace=True)  # drop unneeded columns\n",
    "\n",
    "    saveDir = MPutils.get_saving_dir(\n",
    "        f\"OUTPUT/MP/05-classifiers/DataV4/{dataName}/\"\n",
    "    )\n",
    "\n",
    "    ## HOLDOUT SET ONLY\n",
    "    x_h, y_h = getXY(df_h)\n",
    "\n",
    "    # Ensure all arguments are picklable -- due to BrokenProcessPool: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n",
    "    picklable_lScorers = [scorer for scorer in lScorersBinary]\n",
    "    picklable_lClassifiers = [classifier for classifier in lClassifiers]\n",
    "\n",
    "    dfRHold = classify_MP(\n",
    "        X=x_h,\n",
    "        y=y_h,\n",
    "        lScorers=picklable_lScorers,\n",
    "        lClassifiers=picklable_lClassifiers,\n",
    "        lTrees=lTrees,\n",
    "        lMD=lMD,\n",
    "        lCV=lCV,\n",
    "    )\n",
    "    \n",
    "    dfRHold[\"Title\"] = f\"{dataName}_Holdout\"\n",
    "    dfRHold['RunType']='Holdout'\n",
    "\n",
    "    dfRHold[\"MainDataset\"] = dataName\n",
    "    dfRHold[\"date\"] = datetime.today()\n",
    "\n",
    "    holdFile = f\"{saveDir}CA_{dataName}_Holdout.csv\"\n",
    "    dfRHold = updateExistingDF(dfRHold, holdFile, save=True)\n",
    "\n",
    "    ## Full SET ONLY\n",
    "    x_F, y_F = getXY(df_full)\n",
    "\n",
    "    dfRFull = classify_MP(\n",
    "        X=x_F,\n",
    "        y=y_F,\n",
    "        lScorers=lScorersBinary,\n",
    "        lClassifiers=lClassifiers,\n",
    "        lTrees=lTrees,\n",
    "        lMD=lMD,\n",
    "        lCV=lCV,\n",
    "    )\n",
    "    dfRFull[\"Title\"] = f\"{dataName}_Full\"\n",
    "    dfRFull[\"RunType\"] = \"Full\"\n",
    "    dfRFull[\"MainDataset\"] = dataName\n",
    "    dfRFull[\"date\"] = datetime.today()\n",
    "\n",
    "    fulldataFile= f\"{saveDir}CA_{dataName}_Full.csv\"\n",
    "    dfRFull = updateExistingDF(dfRFull, fulldataFile, save=True)\n",
    "\n",
    "    ## BORUTA Feature Selection\n",
    "\n",
    "    x_Tr, y_Tr = getXY(df_tr)\n",
    "    lBrtResults = []\n",
    "    for boruta_md in tqdm(lBrt_MD[:],desc='Boruta MD Loop'):\n",
    "        # run brouta = get true and top feat\n",
    "        trueFeat, topFeat = boruta_fs(\n",
    "            X=x_Tr.values,\n",
    "            y=y_Tr,\n",
    "            feat_list=x_Tr.columns,\n",
    "            trees=brt_trees,\n",
    "            ittr=brt_iter,\n",
    "            threshold=brt_thres,\n",
    "            top_rank=brt_toprank,\n",
    "            verbose=0,\n",
    "            model=RandomForestClassifier(\n",
    "                n_jobs=-1, class_weight=\"balanced\", max_depth=boruta_md, random_state=42\n",
    "            ),\n",
    "            fileName=f\"{saveDir}FS_{dataName}_Boruta_T{brt_trees}_itrr{brt_iter}_th{brt_thres}_topR{brt_toprank}_MD{boruta_md}.csv\",\n",
    "        )\n",
    "\n",
    "        ## Test Brouta Features\n",
    "        x_TsMain, y_Ts = getXY(df_ts)\n",
    "\n",
    "        x_Ts_True = x_TsMain[trueFeat]\n",
    "        x_Ts_Top = x_TsMain[topFeat]\n",
    "\n",
    "        # True Feat\n",
    "        if len(trueFeat) > 0:\n",
    "            dfR_True = classify_MP(\n",
    "                X=x_Ts_True,\n",
    "                y=y_Ts,\n",
    "                lScorers=lScorersBinary,\n",
    "                lClassifiers=lClassifiers,\n",
    "                lTrees=lTrees,\n",
    "                lMD=lMD,\n",
    "                lCV=lCV,\n",
    "            )\n",
    "            dfR_True[\"Title\"] = f\"{dataName}_Boruta_True\"\n",
    "            dfR_True[\"brt_md\"] = boruta_md\n",
    "            dfR_True['brt_nTrue'] = len(trueFeat)\n",
    "            dfR_True['brt_nTop'] = len(topFeat)\n",
    "            dfR_True[\"RunType\"] = \"Boruta_True\"\n",
    "            lBrtResults.append(dfR_True)\n",
    "\n",
    "        # Top Feat\n",
    "        if len(topFeat) > 0:\n",
    "            dfR_Top = classify_MP(\n",
    "                X=x_Ts_Top,\n",
    "                y=y_Ts,\n",
    "                lScorers=lScorersBinary,\n",
    "                lClassifiers=lClassifiers,\n",
    "                lTrees=lTrees,\n",
    "                lMD=lMD,\n",
    "                lCV=lCV,\n",
    "            )\n",
    "            dfR_Top[\"Title\"] = f\"{dataName}_Boruta_Top\"\n",
    "\n",
    "            dfR_Top[\"brt_md\"] = boruta_md\n",
    "            dfR_Top['brt_nTrue'] = len(trueFeat)\n",
    "            dfR_Top[\"brt_nTop\"] = len(topFeat)\n",
    "            dfR_Top[\"RunType\"] = \"Boruta_Top\"\n",
    "            lBrtResults.append(dfR_Top)\n",
    "\n",
    "    dfCLFRun = pd.concat([dfRHold, dfRFull]+lBrtResults)\n",
    "\n",
    "    dfCLFRun[\"MainDataset\"] = dataName\n",
    "    dfCLFRun[\"date\"] = datetime.today()\n",
    "    dfCLFRun[\"brt_params\"] = (\n",
    "        f\"T{brt_trees}_itrr{brt_iter}_th{brt_thres}_topR{brt_toprank}\"\n",
    "    )\n",
    "\n",
    "    clfFile = f\"{saveDir}CLFRun_{dataName}_Results.csv\"\n",
    "\n",
    "    dfCLFRun = updateExistingDF(dfCLFRun,clfFile,save=False)\n",
    "    dfCLFRun = MPutils.reorder_columns(dfCLFRun, [\"MainDataset\", \"Title\", \"date\",'brt_nTrue','brt_nTop'])\n",
    "    dfCLFRun.to_csv(clfFile, index=False)\n",
    "    \n",
    "    # lRunDataFrames.append(dfCLFRun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Archived --- April 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfCombRes = pd.concat(lRunDataFrames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfCombRes[\"classifier\"] = dfCombRes[\"param_clf\"].apply(lambda x: x.__str__().split(\"(\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lColFirst = [\n",
    "#     \"MainDataset\",\n",
    "#     \"Title\",\n",
    "#     # \"date\",\n",
    "#     # \"classifier\",\n",
    "#     'RunType',\n",
    "#     \"cv\",\n",
    "#     # \"brt_nTrue\",\n",
    "#     # \"brt_nTop\",\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfCombRes = MPutils.reorder_columns(dfCombRes, lColFirst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfCombRes.to_csv('OUTPUT/MP/05-classifiers/DataV3/CLFRunCombined.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lColsSel = lColFirst + [\n",
    "#     x\n",
    "#     # for x in dfCombRes\n",
    "#     for x in dfRHold\n",
    "#     if (x.startswith(\"mean_test\") or x.startswith(\"param_\") or x.startswith(\"brt_\"))\n",
    "#     and  x not in lColFirst\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfCombRes[lColsSel].to_csv(\n",
    "#     \"OUTPUT/MP/05-classifiers/DataV3/CLFRunCombined_SelCol.csv\", index=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holdoutset - validation testing - Boruta Tested Best Feature + Sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalfeat = 'FS_dfcmpltPreLC4_Boruta_T1000_itrr500_th100_topR5_MD3'\n",
    "valSelTests = {\n",
    "    \"dfcmpltPreLC4\":[\n",
    "        globalfeat\n",
    "    ],\n",
    "    \"dfcmpltPreLC4_SITE1\":[\n",
    "        globalfeat,\n",
    "        'FS_dfcmpltPreLC4_SITE1_Boruta_T1000_itrr500_th100_topR5_MD3'\n",
    "    ],\n",
    "    \"dfcmpltPreLC4_SITE2\":[\n",
    "        globalfeat,\n",
    "        'FS_dfcmpltPreLC4_SITE2_Boruta_T1000_itrr500_th100_topR5_MD3'\n",
    "    ],\n",
    "    \"dfcmpltPreLC4_SITE3\":[\n",
    "        globalfeat,\n",
    "        'FS_dfcmpltPreLC4_SITE3_Boruta_T1000_itrr500_th100_topR5_MD7'\n",
    "    ],\n",
    "    \"dfcmpltPreLC4_SITE4\":[\n",
    "        globalfeat,\n",
    "        'FS_dfcmpltPreLC4_SITE4_Boruta_T1000_itrr500_th100_topR5_MD3'\n",
    "    ],\n",
    "    \"dfcmpltPreLC4_SITE5\":[\n",
    "        globalfeat,\n",
    "        'FS_dfcmpltPreLC4_SITE5_Boruta_T1000_itrr500_th100_topR5_MD5'\n",
    "    ],\n",
    "    \"dfcmpltPreLC4_SITE6\":[\n",
    "        globalfeat,\n",
    "        'FS_dfcmpltPreLC4_SITE6_Boruta_T1000_itrr500_th100_topR5_MD3'\n",
    "    ],\n",
    "    \"dfcmpltPreLC4_SITE7\":[\n",
    "        globalfeat,\n",
    "        'FS_dfcmpltPreLC4_SITE7_Boruta_T1000_itrr500_th100_topR5_MD3'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lDT_7 = MPutils.getTrueFeatList(\n",
    "# #     \"OUTPUT/MP/05-classifiers/DataV2/DT/FS_DT_Boruta_T1000_itrr500_th100_topR5_MD7.csv\"\n",
    "\n",
    "\n",
    "# lCmplt = MPutils.getTrueFeatList(\n",
    "#     \"OUTPUT/MP/05-classifiers/DataV3/dfcmplt/FS_dfcmplt_Boruta_T1000_itrr500_th100_topR5_MD7.csv\"\n",
    "# )\n",
    "\n",
    "\n",
    "# lColFS = lCmplt\n",
    "# # dataName = \"T81\"\n",
    "# selFeatName = \"FS_dfcmplt_Boruta_T1000_itrr500_th100_topR5_MD7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../Data/DataV3/TTS/'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13fa19e96f9d499aab97a4182e14ebcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DataSet Main Outer Loop:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mtrx/miniconda3/envs/clust/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "lRunDataFrames = []\n",
    "for selData in tqdm(valSelTests.keys(),desc='DataSet Main Outer Loop'):\n",
    "    for selFeatName in valSelTests[selData]:\n",
    "\n",
    "        df_h = load_dataset_to_df(f\"{dataDir}{selData}_Holdout.arrow\", verbose=True)\n",
    "\n",
    "        lColDrop = [\"__index_level_0__\", \"LC_STATUS_SITE\",'SITE']\n",
    "\n",
    "        df_h.drop(df_h[df_h[\"LC_STATUS\"] == 2].index, inplace=True)  # drop HC\n",
    "\n",
    "        # df_h[\"LC_STATUS\"] = df_h[\"LC_STATUS\"].apply(\n",
    "        #     lambda x: 1 if x == \"LC_POS\" else 0\n",
    "        # )  # Convert to 0==LCNeg, 1==LCPos\n",
    "\n",
    "        for c in lColDrop:\n",
    "            if c in df_h.columns:\n",
    "                df_h.drop(columns=[c], inplace=True)\n",
    "        # df_h.drop(columns=lColDrop, inplace=True)  # drop unneeded columns\n",
    "\n",
    "        saveDir = MPutils.get_saving_dir(\n",
    "            f\"OUTPUT/MP/05-classifiers/DataV4/{selData}/\"\n",
    "        )\n",
    "\n",
    "        featDir= selFeatName.replace('FS_','').split('_Boruta')[0]\n",
    "        lColFS = MPutils.getTrueFeatList(f\"OUTPUT/MP/05-classifiers/DataV4/{featDir}/{selFeatName}.csv\")\n",
    "        \n",
    "        ## HOLDOUT SET ONLY\n",
    "        x_h, y_h = getXY(df_h)\n",
    "        x_h = x_h[lColFS]\n",
    "\n",
    "        dfRHold = classify_MP(\n",
    "            X=x_h,\n",
    "            y=y_h,\n",
    "            lScorers=lScorersBinary,\n",
    "            lClassifiers=lClassifiers,\n",
    "            lTrees=lTrees,\n",
    "            lMD=lMD,\n",
    "            lCV=lCV,\n",
    "        )\n",
    "        dfRHold[\"Title\"] = f\"{selData}_HoldoutVal\"\n",
    "        dfRHold['RunType']='HoldoutVal'\n",
    "        dfRHold[\"FeatureSet\"] = selFeatName\n",
    "        dfRHold['date']=datetime.today()\n",
    "        dfRHold[\"classifier\"] = dfRHold[\"param_clf\"].apply(lambda x: x.__str__().split(\"(\")[0])\n",
    "        dfRHold[\"MainDataset\"] = selData\n",
    "\n",
    "        lColFirst = [\n",
    "            \"MainDataset\",\n",
    "            \"Title\",\n",
    "            'FeatureSet',\n",
    "            \"date\",\n",
    "            \"classifier\",\n",
    "            \"RunType\",\n",
    "            \"cv\",\n",
    "        ]\n",
    "        dfRHold = MPutils.reorder_columns(dfRHold, lColFirst)\n",
    "\n",
    "        ## Export\n",
    "        dfRHold.to_csv(f\"{saveDir}Val_{selData}_HoldoutVal_{selFeatName}.csv\", index=False)\n",
    "\n",
    "        ## Select Columns\n",
    "        lColsSel = lColFirst + [\n",
    "            x\n",
    "            for x in dfRHold\n",
    "            if (x.startswith(\"mean_test\") or x.startswith(\"param_\") or x.startswith(\"brt_\"))\n",
    "            and x not in lColFirst\n",
    "        ]\n",
    "\n",
    "        dfRHold[lColsSel].to_csv(\n",
    "            f\"{saveDir}Val_{selData}_HoldoutVal_{selFeatName}_SelCol.csv\",\n",
    "            index=False,\n",
    "        )\n",
    "\n",
    "    # lRunDataFrames.append(dfRHold)\n",
    "\n",
    "        ### Feature Importance\n",
    "\n",
    "        clf = RandomForestClassifier(n_estimators=1000, max_depth=10, random_state=42)\n",
    "        clf.fit(x_h, y_h)\n",
    "        feature_importances = clf.feature_importances_\n",
    "        feature_importances = pd.Series(feature_importances, index=x_h.columns).sort_values(\n",
    "            ascending=False\n",
    "        )\n",
    "\n",
    "        dfFeatureImp = pd.DataFrame(feature_importances).reset_index()\n",
    "        dfFeatureImp.columns = [\"Feature\", \"Importance\"]\n",
    "        dfFeatureImp[\"Importance\"] = dfFeatureImp[\"Importance\"].round(4)\n",
    "        dfFeatureImp[\"Rank\"] = dfFeatureImp.rank(ascending=False)[\"Importance\"].astype(int)\n",
    "        dfFeatureImp = dfFeatureImp[[\"Rank\", \"Feature\", \"Importance\"]]\n",
    "\n",
    "        dfFeatureImp.to_csv(\n",
    "            f\"{saveDir}FR_{selData}_HoldoutVal_{selFeatName}.csv\", index=False\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R2024_LCO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
